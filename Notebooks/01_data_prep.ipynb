{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4abcc01",
   "metadata": {},
   "source": [
    "# Notebook 01: Data Preparation & Audit\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Ingestion](#setup-and-data-ingestion)\n",
    "    * Load Raw Data\n",
    "    * Structural Audit (Shape, Dtypes)\n",
    "2. [Data Sanitation](#data-sanitation)\n",
    "    * Missing Value Check\n",
    "    * Duplicate Removal\n",
    "3. [Temporal Alignment](#temporal-alignment)\n",
    "    * UTC Standardization\n",
    "    * Date Normalization\n",
    "4. [Data Integration](#data-integration)\n",
    "    * Sentiment Merge\n",
    "    * Neutral Fill Strategy\n",
    "5. [Outlier Management](#outlier-management)\n",
    "    * Leverage & PnL Extreme Value Detection\n",
    "    * Capping Policy Application\n",
    "6. [Engineering Reasoning Log](#engineering-reasoning-log)\n",
    "7. [Export](#export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4e92c8",
   "metadata": {},
   "source": [
    "### 1. Setup and Data Ingestion <a id=\"setup-and-data-ingestion\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc43549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trader Data Shape: (211224, 16)\n",
      "Trader Data Columns: ['Account', 'Coin', 'Execution Price', 'Size Tokens', 'Size USD', 'Side', 'Timestamp IST', 'Start Position', 'Direction', 'Closed PnL', 'Transaction Hash', 'Order ID', 'Crossed', 'Fee', 'Trade ID', 'Timestamp']\n",
      "Trader Data Types:\n",
      "Account                 str\n",
      "Coin                    str\n",
      "Execution Price     float64\n",
      "Size Tokens         float64\n",
      "Size USD            float64\n",
      "Side                    str\n",
      "Timestamp IST           str\n",
      "Start Position      float64\n",
      "Direction               str\n",
      "Closed PnL          float64\n",
      "Transaction Hash        str\n",
      "Order ID              int64\n",
      "Crossed                bool\n",
      "Fee                 float64\n",
      "Trade ID            float64\n",
      "Timestamp           float64\n",
      "dtype: object\n",
      "------------------------------\n",
      "Sentiment Data Shape: (2644, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "RAW_DATA_PATH = '../data'\n",
    "PROCESSED_DATA_PATH = '../data/processed'\n",
    "os.makedirs(PROCESSED_DATA_PATH, exist_ok=True)\n",
    "\n",
    "trader_df = pd.read_csv(os.path.join(RAW_DATA_PATH, 'historical_data.csv'))\n",
    "sentiment_df = pd.read_csv(os.path.join(RAW_DATA_PATH, 'fear_greed_index.csv'))\n",
    "\n",
    "print(f\"Trader Data Shape: {trader_df.shape}\")\n",
    "print(f\"Trader Data Columns: {trader_df.columns.tolist()}\")\n",
    "print(f\"Trader Data Types:\\n{trader_df.dtypes}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Sentiment Data Shape: {sentiment_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c8567",
   "metadata": {},
   "source": [
    "### 2. Data Sanitation <a id=\"data-sanitation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618e26f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values:\n",
      "Series([], dtype: int64)\n",
      "Duplicate Rows Detected: 0\n"
     ]
    }
   ],
   "source": [
    "null_counts = trader_df.isnull().sum()\n",
    "print(f\"Null Values:\\n{null_counts[null_counts > 0]}\")\n",
    "\n",
    "dup_count = trader_df.duplicated().sum()\n",
    "print(f\"Duplicate Rows Detected: {dup_count}\")\n",
    "\n",
    "trader_df = trader_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf9032",
   "metadata": {},
   "source": [
    "### 3. Temporal Alignment <a id=\"temporal-alignment\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c4ebea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trader_df['datetime_utc'] = pd.to_datetime(trader_df['Timestamp'], unit='ms', utc=True)\n",
    "trader_df['date'] = trader_df['datetime_utc'].dt.normalize()\n",
    "\n",
    "sentiment_df['date'] = pd.to_datetime(sentiment_df['date'], utc=True)\n",
    "sentiment_clean = sentiment_df[['date', 'value', 'classification']].rename(\n",
    "    columns={'value': 'sentiment_score', 'classification': 'sentiment_class'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2efe1f",
   "metadata": {},
   "source": [
    "### 4. Data Integration <a id=\"data-integration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07eff0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    left=trader_df,\n",
    "    right=sentiment_clean,\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "merged_df['sentiment_score'] = merged_df['sentiment_score'].fillna(50)\n",
    "merged_df['sentiment_class'] = merged_df['sentiment_class'].fillna('Neutral')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb55dddf",
   "metadata": {},
   "source": [
    "### 5. Outlier Management <a id=\"outlier-management\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bfe4eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Closed PnL     pnl_capped\n",
      "count  211224.000000  211224.000000\n",
      "mean       48.749001      31.306126\n",
      "std       919.164828     134.809828\n",
      "min   -117990.104100    -140.766890\n",
      "25%         0.000000       0.000000\n",
      "50%         0.000000       0.000000\n",
      "75%         5.792797       5.792797\n",
      "max    135329.090100    1023.315314\n"
     ]
    }
   ],
   "source": [
    "def cap_outliers(series, lower_quantile=0.01, upper_quantile=0.99):\n",
    "    lower_limit = series.quantile(lower_quantile)\n",
    "    upper_limit = series.quantile(upper_quantile)\n",
    "    return series.clip(lower=lower_limit, upper=upper_limit)\n",
    "\n",
    "merged_df['leverage_capped'] = cap_outliers(merged_df['Size USD'] / merged_df['Start Position'].replace(0, np.nan))\n",
    "merged_df['pnl_capped'] = cap_outliers(merged_df['Closed PnL'])\n",
    "\n",
    "print(merged_df[['Closed PnL', 'pnl_capped']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838dc0a8",
   "metadata": {},
   "source": [
    "###  6. Engineering Reasoning Log\n",
    "<a id=\"engineering-reasoning-log\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd86a8d",
   "metadata": {},
   "source": [
    "| **Phase** | **Action Taken** | **Engineering Justification** |\n",
    "| --- | --- | --- |\n",
    "| **Ingestion** | Loaded raw CSVs and audited types. | Ensures schema consistency and prevents downstream failures caused by silent type mismatches (e.g., strings in float columns). |\n",
    "| **Sanitation** | Removed full-row duplicates. | Eliminates redundant transaction logs that artificially inflate trade frequency and volume metrics. |\n",
    "| **Alignment** | Converted Unix MS to UTC Datetime. | Standardizes diverse timezones into a single global reference frame to ensure accurate event sequencing. |\n",
    "| **Integration** | Left Join on UTC Date; Filled Missing Sentiment with 50 (Neutral). | Preserves all trade data while handling data gaps conservatively; assumes market neutrality when sentiment signal is absent. |\n",
    "| **Outlier Logic** | Applied 1st/99th Percentile Clipping to PnL and Leverage. | Mitigates the impact of \"fat-finger\" errors or liquidation wicks that would otherwise skew mean/variance calculations in the model. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c88af1",
   "metadata": {},
   "source": [
    "### 7.Export <a id=\"export\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae8ff59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: ../data/processed\\01_merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(PROCESSED_DATA_PATH, '01_merged_data.csv')\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(f\"Data saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
